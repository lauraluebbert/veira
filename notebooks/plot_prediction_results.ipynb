{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8db85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from upsetplot import UpSet, from_indicators\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb99f3e",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"XXX\"\n",
    "\n",
    "models = ['Random Forest', 'RAG', 'gpt-oss-20b', 'gpt-oss-120b', 'llama3.1-70b', 'deepseek-r1-70b']\n",
    "\n",
    "# Define a main color for each model\n",
    "main_colors = [\"#4a6741\", \"#818181\", \"#3182bd\", \"#8856a7\", \"darkorange\", \"#f03b20\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_date = \"XXX\"\n",
    "data_path = \"XXX\"\n",
    "data_df = pd.read_csv(data_path, low_memory=False)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathogen = \"all-viral\"\n",
    "train_test_data_folder = f\"{data_folder}/test_train_splits\"\n",
    "\n",
    "test_data_path = f\"{train_test_data_folder}/X_test_{pathogen}_rf.pkl\"\n",
    "test_df = pd.read_pickle(test_data_path)\n",
    "\n",
    "# Add ground truth labels to test_df\n",
    "test_df = test_df.merge(data_df[['record_id','all-viral_label']], on='record_id', how='left')\n",
    "\n",
    "Y_TRUE = test_df['all-viral_label']\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc736fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model breakdowns for LLMs\n",
    "temp = 0.5\n",
    "prompt = \"short\"\n",
    "\n",
    "def get_result_paths(model):\n",
    "    return [\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge\",\n",
    "        # f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge_json2text\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/llm_training_summary_subset_v3\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test_rf/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/llm_training_summary_subset_rf_v3\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge_rag\",\n",
    "        # f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge_rag_json2text\",\n",
    "    ]\n",
    "\n",
    "# For supplementary figures\n",
    "def get_result_paths_supp(model):\n",
    "    return [\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge_json2text\",\n",
    "        # f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/llm_training_summary_subset_v3\",\n",
    "        # f\"{data_folder}/model_llm/{model}/data_test_rf/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/llm_training_summary_subset_rf_v3\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge_rag\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge_rag_json2text\",\n",
    "    ]\n",
    "\n",
    "def get_result_paths_all(model):\n",
    "    return [\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge_json2text\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/llm_training_summary_subset_v3\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test_rf/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/llm_training_summary_subset_rf_v3\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge_rag\",\n",
    "        f\"{data_folder}/model_llm/{model}/data_test/system_prompt_{prompt}/temp_{str(temp).replace(\".\", \"-\")}/no_knowledge_rag_json2text\",\n",
    "    ]\n",
    "\n",
    "# Rename breakdowns in plots\n",
    "k_naming_dict = {\n",
    "    \"no_knowledge\": \"zero-shot\",\n",
    "    \"no_knowledge_json2text\": \"zero-shot\\n(natural language)\",\n",
    "    \"llm_training_summary_subset_v2\": \"medical context\",\n",
    "    \"llm_training_summary_subset_rf_v2\": \"medical context + RF\",\n",
    "    \"llm_training_summary_subset_v3\": \"medical context\",\n",
    "    \"llm_training_summary_subset_rf_v3\": \"medical context + RF\",\n",
    "    \"no_knowledge_rag\": \"RAG\",\n",
    "    \"no_knowledge_rag_json2text\": \"RAG\\n(natural language)\",\n",
    "}\n",
    "\n",
    "rag_label = \"RAG (w/o LLM)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69febffa",
   "metadata": {},
   "source": [
    "# Plot NaN/unknown/yes/no 'viral' results returned by LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_dict = {}   # {label: {run_id: Series}}\n",
    "labels = []              # x-axis labels aligned to insertion order\n",
    "RUN_IDS = [1, 2, 3]\n",
    "\n",
    "def normalize_label(val):\n",
    "    return str(val).strip().lower()\n",
    "\n",
    "for model in models:\n",
    "    if model in (\"Random Forest\", \"RAG\"):\n",
    "        continue\n",
    "\n",
    "    paths = get_result_paths_all(model)\n",
    "    for path in paths:\n",
    "        per_run_counts = {}  # run_id -> Series\n",
    "        any_data = False\n",
    "\n",
    "        for run_id in RUN_IDS:\n",
    "            path_to_csv = f\"{path}/{model}_run0{run_id}_predictions.csv\"\n",
    "            if not os.path.exists(path_to_csv):\n",
    "                continue\n",
    "\n",
    "            pred_df = pd.read_csv(path_to_csv)\n",
    "            if \"viral\" not in pred_df.columns:\n",
    "                continue\n",
    "\n",
    "            vals = [normalize_label(v) for v in pred_df[\"viral\"].tolist()]\n",
    "            if len(vals) == 0:\n",
    "                continue\n",
    "\n",
    "            vc = pd.Series(vals).value_counts(dropna=False)\n",
    "            per_run_counts[run_id] = vc\n",
    "            any_data = True\n",
    "\n",
    "        if not any_data:\n",
    "            continue\n",
    "\n",
    "        knowledge_type = path.split(\"/\")[-1]\n",
    "        nice_name = k_naming_dict.get(knowledge_type, knowledge_type)\n",
    "        label = f\"{model} {nice_name}\"\n",
    "\n",
    "        value_counts_dict[label] = per_run_counts\n",
    "        labels.append(label)\n",
    "\n",
    "# --- Fixed class order ---\n",
    "CLASS_ORDER = [\"yes\", \"no\", \"unknown\", \"nan\"]  # desired stack order (bottom -> top)\n",
    "\n",
    "# Build tensor: (n_runs, n_labels, n_classes) in the fixed order\n",
    "n_labels = len(labels)\n",
    "n_classes = len(CLASS_ORDER)\n",
    "n_runs = len(RUN_IDS)\n",
    "\n",
    "plot_data = np.zeros((n_runs, n_labels, n_classes), dtype=float)\n",
    "\n",
    "for li, label in enumerate(labels):\n",
    "    per_run = value_counts_dict[label]  # dict run_id -> Series\n",
    "    for ri, run_id in enumerate(RUN_IDS):\n",
    "        vc = per_run.get(run_id, pd.Series(dtype=float))\n",
    "        # Ensure VC keys are normalized strings\n",
    "        vc_norm = pd.Series({normalize_label(k): v for k, v in vc.to_dict().items()})\n",
    "        for ci, cls in enumerate(CLASS_ORDER):\n",
    "            plot_data[ri, li, ci] = float(vc_norm.get(cls, 0))\n",
    "\n",
    "# Colors for classes (keep as provided)\n",
    "custom_colors = [\n",
    "    \"darkblue\",\n",
    "    \"cornflowerblue\",\n",
    "    \"grey\",\n",
    "    \"tab:red\",\n",
    "]\n",
    "COLOR_MAP = {cls: custom_colors[i % len(custom_colors)] for i, cls in enumerate(CLASS_ORDER)}\n",
    "\n",
    "# Plot: 3 close-by stacked bars per label (small gap between bars)\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "x = np.arange(n_labels)\n",
    "bar_width = 0.25\n",
    "gap = 0.03  # small space between the 3 bars within each label group\n",
    "\n",
    "# Offsets to center the 3 bars around each label position\n",
    "offsets = np.linspace(\n",
    "    -((n_runs - 1) * (bar_width + gap)) / 2,\n",
    "    ((n_runs - 1) * (bar_width + gap)) / 2,\n",
    "    n_runs\n",
    ")\n",
    "\n",
    "# draw stacks per run\n",
    "for ri, run_id in enumerate(RUN_IDS):\n",
    "    bottoms = np.zeros(n_labels)\n",
    "    for ci, cls in enumerate(CLASS_ORDER):\n",
    "        ax.bar(\n",
    "            x + offsets[ri],\n",
    "            plot_data[ri, :, ci],\n",
    "            width=bar_width,\n",
    "            bottom=bottoms,\n",
    "            label=cls if (ri == 0) else None,  # legend once\n",
    "            color=COLOR_MAP[cls],\n",
    "            edgecolor=\"none\",\n",
    "        )\n",
    "        bottoms += plot_data[ri, :, ci]\n",
    "\n",
    "ax.margins(x=0.01)\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Model Output for Viral Predictions\", fontweight=\"bold\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "\n",
    "# Legend for classes (runs encoded by side-by-side bars)\n",
    "handles, class_labels = ax.get_legend_handles_labels()\n",
    "legend = ax.legend(handles, class_labels, title=\"Value\", loc=\"lower left\", ncol=2)\n",
    "legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"figures/LLM_viral_output_value_counts.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222493d",
   "metadata": {},
   "source": [
    "# Prediction histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb70a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(y_scores, y_labels, ax, title, legend=True, fontsize=12, include_unknowns=True):\n",
    "    linestyles = ['solid', 'dashed', 'dotted']\n",
    "    bins = 20\n",
    "    for i, (score_list, label_list) in enumerate(zip(y_scores, y_labels)):\n",
    "        linestyle = linestyles[i]\n",
    "        if i == 0:\n",
    "            ax.hist(\n",
    "                [score for score, label in zip(score_list, label_list) if label == \"yes\"],\n",
    "                bins=bins,\n",
    "                label=\"yes\",\n",
    "                color=\"red\",\n",
    "                histtype='step',\n",
    "                linestyle=linestyle\n",
    "            )\n",
    "            ax.hist(\n",
    "                [score for score, label in zip(score_list, label_list) if label == \"no\"],\n",
    "                bins=bins,\n",
    "                label=\"no\",\n",
    "                color=\"black\",\n",
    "                histtype='step',\n",
    "                linestyle=linestyle\n",
    "            )\n",
    "            if include_unknowns:\n",
    "                ax.hist(\n",
    "                    [score for score, label in zip(score_list, label_list) if label == \"unkown\"],\n",
    "                    bins=bins,\n",
    "                    label=\"unkown\",\n",
    "                    color=\"grey\",\n",
    "                    histtype='stepfilled',\n",
    "                    linestyle=linestyle\n",
    "                )\n",
    "        else:\n",
    "            ax.hist(\n",
    "                [score for score, label in zip(score_list, label_list) if label == \"yes\"],\n",
    "                bins=bins,\n",
    "                color=\"red\",\n",
    "                histtype='step',\n",
    "                linestyle=linestyle\n",
    "            )\n",
    "            ax.hist(\n",
    "                [score for score, label in zip(score_list, label_list) if label == \"no\"],\n",
    "                bins=bins,\n",
    "                color=\"black\",\n",
    "                histtype='step',\n",
    "                linestyle=linestyle\n",
    "            )\n",
    "            if include_unknowns:\n",
    "                ax.hist(\n",
    "                    [score for score, label in zip(score_list, label_list) if label == \"unknown\"],\n",
    "                    bins=bins,\n",
    "                    color=\"grey\",\n",
    "                    histtype='stepfilled',\n",
    "                    linestyle=linestyle\n",
    "                )\n",
    "\n",
    "    # ax.set_title(title, fontsize=fontsize)\n",
    "    if legend:\n",
    "        ax.legend(title=\"Predicted Viral\", fontsize=fontsize, title_fontsize=fontsize, loc=\"upper right\")\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "    ax.margins(x=0.01)\n",
    "    ax.grid(True, color='grey', linestyle='--', linewidth=0.7, alpha=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_xlim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b774d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_prediction_histograms(\n",
    "    models,\n",
    "    include_unknowns=False,\n",
    "    test_df=None,\n",
    "    train_test_data_folder=None,\n",
    "    pathogen=None,\n",
    "    get_result_paths=None,\n",
    "    k_naming_dict=None,\n",
    "    Y_TRUE=None,\n",
    "    figsize=None,\n",
    "    save_path=\"figures/LLM_test_data_preds.png\",\n",
    "    y_title_padding=0.047\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots histograms of predicted viral probabilities for a list of models.\n",
    "    \n",
    "    Parameters:\n",
    "        models (list): List of model names to plot.\n",
    "        include_unknowns (bool): Whether to include 'unknown' predictions in the histograms.\n",
    "        test_df (pd.DataFrame): DataFrame with test set and 'all-viral_label' and 'record_id' columns.\n",
    "        train_test_data_folder (str): Path to folder with prediction files.\n",
    "        pathogen (str): Pathogen name for file naming.\n",
    "        get_result_paths (callable): Function to get result paths for a model.\n",
    "        k_naming_dict (dict): Dictionary mapping knowledge type to display name.\n",
    "        Y_TRUE (list/array): Ground truth labels for test set.\n",
    "        save_path (str): Path to save the resulting figure.\n",
    "    \"\"\"\n",
    "    # Calculate number of rows for the subplot grid\n",
    "    nrows = (len(models)-2)*len(get_result_paths(models[0]))+1\n",
    "    if figsize==None:\n",
    "        figsize=(14, 2*nrows)\n",
    "    fig, axs = plt.subplots(figsize=figsize, nrows=nrows, ncols=2, sharex=True)\n",
    "    fontsize = 12\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.20)\n",
    "\n",
    "    # Define consistent bins for all histograms (0-100 for probabilities as in your data)\n",
    "    hist_bins = np.linspace(0, 100, 21)  # 20 bins from 0 to 100\n",
    "\n",
    "    # Get record IDs of confirmed pos/neg patients\n",
    "    pos_record_ids = set(test_df.loc[test_df['all-viral_label'] == 1, 'record_id'])\n",
    "    neg_record_ids = set(test_df.loc[test_df['all-viral_label'] == 0, 'record_id'])\n",
    "\n",
    "    row_idx = 0\n",
    "    for model in models:\n",
    "\n",
    "        if model == \"Random Forest\":\n",
    "            seeds = [\"\", \"_02\", \"_03\"]\n",
    "            y_scores_pos, y_scores_neg = [], []\n",
    "            y_labels_pos, y_labels_neg = [], []\n",
    "\n",
    "            for seed in seeds:\n",
    "                path_to_pkl = f\"{train_test_data_folder}/X_test_{pathogen}_rf{seed}.pkl\"\n",
    "                try:\n",
    "                    with open(path_to_pkl, \"rb\") as f:\n",
    "                        pred_df = pickle.load(f)\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"Warning: File not found: {path_to_pkl}\")\n",
    "                    continue\n",
    "\n",
    "                if not len(test_df) == len(pred_df):\n",
    "                    continue\n",
    "\n",
    "                # Filter positive and negative samples\n",
    "                subset_pos = pred_df[pred_df['record_id'].isin(pos_record_ids)]\n",
    "                subset_neg = pred_df[pred_df['record_id'].isin(neg_record_ids)]\n",
    "\n",
    "                # Ensure numeric dtype\n",
    "                y_score_list_pos = pd.to_numeric(subset_pos['probability_of_viral_rf'], errors='coerce').dropna()\n",
    "                y_score_list_neg = pd.to_numeric(subset_neg['probability_of_viral_rf'], errors='coerce').dropna()\n",
    "\n",
    "                y_scores_pos.append(y_score_list_pos)\n",
    "                y_scores_neg.append(y_score_list_neg)\n",
    "\n",
    "                y_label_list_pos = subset_pos['viral_rf']\n",
    "                y_label_list_neg = subset_neg['viral_rf']\n",
    "                y_labels_pos.append(y_label_list_pos)\n",
    "                y_labels_neg.append(y_label_list_neg)\n",
    "\n",
    "            # Plot histograms for positive and negative samples\n",
    "            plot_hist(y_scores_pos, y_labels_pos, axs[row_idx, 0], title=model, legend=False, fontsize=fontsize, include_unknowns=include_unknowns)\n",
    "            plot_hist(y_scores_neg, y_labels_neg, axs[row_idx, 1], title=model, fontsize=fontsize, include_unknowns=include_unknowns)\n",
    "\n",
    "            # Place the row title centered above both subplots, directly above the current row\n",
    "            # Use the y1 of the uppermost axis in the row for the title position\n",
    "            bbox0 = axs[row_idx, 0].get_position()\n",
    "            bbox1 = axs[row_idx, 1].get_position()\n",
    "            y_top = max(bbox0.y0, bbox1.y0)  # Use y0 (bottom) instead of y1 (top) for correct placement\n",
    "            x_left = bbox0.x0\n",
    "            x_right = bbox1.x1\n",
    "            x_center = (x_left + x_right) / 2\n",
    "\n",
    "            # Place the title just above the axes row, with a small offset\n",
    "            fig.text(x_center, \n",
    "                     y_top + y_title_padding,\n",
    "                     model, \n",
    "                     ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "            row_idx += 1\n",
    "\n",
    "        elif model == \"RAG\":\n",
    "            path_to_pkl = f\"{train_test_data_folder}/X_test_{pathogen}_rag.pkl\"\n",
    "            pred_df = pd.read_pickle(path_to_pkl)\n",
    "\n",
    "            # Filter positive and negative samples\n",
    "            subset_pos = pred_df[pred_df['record_id'].isin(pos_record_ids)]\n",
    "            subset_neg = pred_df[pred_df['record_id'].isin(neg_record_ids)]\n",
    "            \n",
    "            # Ensure numeric dtype\n",
    "            y_scores_pos = pd.to_numeric(subset_pos['weighted_averages']*100, errors='coerce').dropna()\n",
    "            y_scores_neg = pd.to_numeric(subset_neg['weighted_averages']*100, errors='coerce').dropna()\n",
    "\n",
    "            y_labels_pos = subset_pos['weighted_averages_round'].map({0: \"no\", 1: \"yes\"})\n",
    "            y_labels_neg = subset_neg['weighted_averages_round'].map({0: \"no\", 1: \"yes\"})\n",
    "\n",
    "            # Plot histograms for positive and negative samples\n",
    "            plot_hist([y_scores_pos], [y_labels_pos], axs[row_idx, 0], title=rag_label, legend=False, fontsize=fontsize, include_unknowns=include_unknowns)\n",
    "            plot_hist([y_scores_neg], [y_labels_neg], axs[row_idx, 1], title=rag_label, legend=False, fontsize=fontsize, include_unknowns=include_unknowns)\n",
    "\n",
    "            # Place the row title centered above both subplots, directly above the current row\n",
    "            bbox0 = axs[row_idx, 0].get_position()\n",
    "            bbox1 = axs[row_idx, 1].get_position()\n",
    "            y_top = max(bbox0.y0, bbox1.y0)\n",
    "            x_left = bbox0.x0\n",
    "            x_right = bbox1.x1\n",
    "            x_center = (x_left + x_right) / 2\n",
    "\n",
    "            fig.text(x_center, \n",
    "                     y_top + y_title_padding,\n",
    "                     rag_label, \n",
    "                     ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "            row_idx += 1\n",
    "\n",
    "        else:\n",
    "            paths = get_result_paths(model)\n",
    "            for i, path in enumerate(paths):\n",
    "\n",
    "                if \"deepseek\" in model and \"_rf\" in path:\n",
    "                    continue\n",
    "\n",
    "                y_scores_pos, y_scores_neg = [], []\n",
    "                y_labels_pos, y_labels_neg = [], []\n",
    "\n",
    "                for run_id in [1, 2, 3]:\n",
    "                    path_to_csv = f\"{path}/{model}_run0{str(run_id)}_predictions.csv\"\n",
    "                    if not os.path.exists(path_to_csv):\n",
    "                        continue\n",
    "                    pred_df = pd.read_csv(path_to_csv)\n",
    "\n",
    "                    y_score_list = pred_df['probability_of_viral']\n",
    "                    if len(y_score_list) != len(Y_TRUE):\n",
    "                        continue\n",
    "\n",
    "                    # Filtering logic for unknowns\n",
    "                    if include_unknowns:\n",
    "                        allowed_labels = ['yes', 'no', 'unknown']\n",
    "                        filtered_pred_df = pred_df[\n",
    "                            pred_df['viral'].isin(allowed_labels) &\n",
    "                            pred_df['probability_of_viral'].notna()\n",
    "                        ]\n",
    "                    else:\n",
    "                        allowed_labels = ['yes', 'no']\n",
    "                        filtered_pred_df = pred_df[\n",
    "                            pred_df['viral'].isin(allowed_labels) &\n",
    "                            pred_df['probability_of_viral'].notna() &\n",
    "                            (pred_df['probability_of_viral'] != 'unknown')\n",
    "                        ]\n",
    "\n",
    "                    # Filter positive and negative samples using row indices\n",
    "                    pos_indices = test_df.index[test_df['all-viral_label'] == 1]\n",
    "                    neg_indices = test_df.index[test_df['all-viral_label'] == 0]\n",
    "\n",
    "                    subset_pos = filtered_pred_df.loc[filtered_pred_df.index.intersection(pos_indices)]\n",
    "                    subset_neg = filtered_pred_df.loc[filtered_pred_df.index.intersection(neg_indices)]\n",
    "\n",
    "                    # Ensure numeric dtype and drop NaNs\n",
    "                    y_score_list_pos = pd.to_numeric(subset_pos['probability_of_viral'], errors='coerce').dropna()\n",
    "                    y_score_list_neg = pd.to_numeric(subset_neg['probability_of_viral'], errors='coerce').dropna()\n",
    "                    \n",
    "                    y_scores_pos.append(y_score_list_pos)\n",
    "                    y_scores_neg.append(y_score_list_neg)\n",
    "\n",
    "                    y_label_list_pos = subset_pos['viral']\n",
    "                    y_label_list_neg = subset_neg['viral']\n",
    "                    y_labels_pos.append(y_label_list_pos)\n",
    "                    y_labels_neg.append(y_label_list_neg)\n",
    "\n",
    "                if len(y_scores_pos) == 0:\n",
    "                    continue\n",
    "\n",
    "                knowledge_type = path.split(\"/\")[-1]\n",
    "                label = f\"{model} ({k_naming_dict[knowledge_type]})\"\n",
    "                plot_hist(y_scores_pos, y_labels_pos, axs[row_idx, 0], title=label, legend=False, fontsize=fontsize, include_unknowns=include_unknowns)\n",
    "                plot_hist(y_scores_neg, y_labels_neg, axs[row_idx, 1], title=label, legend=False, fontsize=fontsize, include_unknowns=include_unknowns)\n",
    "\n",
    "                # Place the row title centered above both subplots, directly above the current row\n",
    "                bbox0 = axs[row_idx, 0].get_position()\n",
    "                bbox1 = axs[row_idx, 1].get_position()\n",
    "                y_top = max(bbox0.y0, bbox1.y0)\n",
    "                x_left = bbox0.x0\n",
    "                x_right = bbox1.x1\n",
    "                x_center = (x_left + x_right) / 2\n",
    "\n",
    "                fig.text(x_center, \n",
    "                        y_top + y_title_padding,\n",
    "                        label, \n",
    "                        ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "                row_idx += 1\n",
    "\n",
    "    # Add labels for the whole plot\n",
    "    fig.text(0.05, 0.5, 'Count', va='center', rotation='vertical', fontsize=fontsize+2)\n",
    "    fig.text(0.5, 0.075, 'Predicted Viral Probability', ha='center', va='center', fontsize=fontsize+2)\n",
    "    fig.text(0.3, 0.91, 'Viral', ha='center', fontsize=fontsize+2)\n",
    "    fig.text(0.7, 0.91, 'Non-viral', ha='center', fontsize=fontsize+2)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "\n",
    "    fig.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59193dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model_prediction_histograms(\n",
    "#     models,\n",
    "#     True,  # include unknowns\n",
    "#     test_df,\n",
    "#     train_test_data_folder,\n",
    "#     pathogen,\n",
    "#     get_result_paths,\n",
    "#     k_naming_dict,\n",
    "#     Y_TRUE,\n",
    "#     save_path=\"figures/LLM_test_data_preds_all.png\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77842983",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_prediction_histograms(\n",
    "    models,\n",
    "    True, # include unknowns\n",
    "    test_df,\n",
    "    train_test_data_folder,\n",
    "    pathogen,\n",
    "    get_result_paths,\n",
    "    k_naming_dict,\n",
    "    Y_TRUE,\n",
    "    figsize=(6.5,26),\n",
    "    y_title_padding=0.045,\n",
    "    save_path=\"figures/LLM_test_data_preds_all.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7035fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_short = ['Random Forest', 'RAG', 'gpt-oss-120b']\n",
    "\n",
    "# plot_model_prediction_histograms(\n",
    "#     models_short,\n",
    "#     False, # include unknowns\n",
    "#     test_df,\n",
    "#     train_test_data_folder,\n",
    "#     pathogen,\n",
    "#     get_result_paths,\n",
    "#     k_naming_dict,\n",
    "#     Y_TRUE,\n",
    "#     figsize=(6.5,13),\n",
    "#     y_title_padding=0.105,\n",
    "#     save_path=\"figures/LLM_test_data_preds.png\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d750d",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef86f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model, generate three shades of its main color for the three paths\n",
    "def get_shades(color, n=3):\n",
    "    # Returns n shades from main (darkest) to lightest color\n",
    "    rgb = mcolors.to_rgb(color)\n",
    "    factors = np.linspace(0.25, 1, n)\n",
    "    shades = [mcolors.to_hex(tuple(1 - (1 - c) * f for c in rgb)) for f in factors]\n",
    "    return shades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb75b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_trues, y_scores, ax, color, label, ls=None):\n",
    "    \"\"\"\n",
    "    y_trues: either a 1D list/array of ground-truth binary labels (0/1)\n",
    "    y_scores: either a 1D list/array of scores OR a list of lists (e.g., [scores1, scores2, scores3])\n",
    "    \"\"\"\n",
    "    # Helper function to check if input is a 1D array-like (not a list of lists)\n",
    "    def is_1d_array_like(x):\n",
    "        if isinstance(x, pd.Series):\n",
    "            return True\n",
    "        if isinstance(x, np.ndarray) and x.ndim == 1:\n",
    "            return True\n",
    "        if isinstance(x, list) and (len(x) == 0 or not isinstance(x[0], (list, np.ndarray, pd.Series))):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # Case 1: Both y_trues and y_scores are 1D arrays/lists\n",
    "    if is_1d_array_like(y_scores) and is_1d_array_like(y_trues):\n",
    "        fpr, tpr, _ = roc_curve(y_trues, y_scores)\n",
    "        auc_value = roc_auc_score(y_trues, y_scores)\n",
    "        # label = f'{label}\\n(AUC = {auc_value:.2f})'\n",
    "        ax.plot(fpr, tpr, label=label, lw=2, color=color, ls=ls)\n",
    "    else:\n",
    "        # Case 2: y_scores is a list of arrays/lists, and y_trues is either a single vector or a list of vectors\n",
    "        fpr_grid = np.linspace(0.0, 1.0, 101)\n",
    "        tpr_stack = []\n",
    "        aucs = []\n",
    "\n",
    "        # If y_trues is a single vector, repeat it for each y_scores entry\n",
    "        if is_1d_array_like(y_trues):\n",
    "            y_trues_list = [y_trues] * len(y_scores)\n",
    "        else:\n",
    "            y_trues_list = y_trues\n",
    "\n",
    "        for yt, ys in zip(y_trues_list, y_scores):\n",
    "            fpr, tpr, _ = roc_curve(yt, ys)\n",
    "            aucs.append(roc_auc_score(yt, ys))\n",
    "            # Interpolate TPR on a common FPR grid\n",
    "            tpr_i = np.interp(fpr_grid, fpr, tpr)\n",
    "            tpr_i[0] = 0.0\n",
    "            tpr_i[-1] = 1.0\n",
    "            tpr_stack.append(tpr_i)\n",
    "\n",
    "        tpr_stack = np.vstack(tpr_stack)\n",
    "        mean_tpr = tpr_stack.mean(axis=0)\n",
    "        lo_tpr = tpr_stack.min(axis=0)\n",
    "        hi_tpr = tpr_stack.max(axis=0)\n",
    "\n",
    "        ax.plot(\n",
    "            fpr_grid,\n",
    "            mean_tpr,\n",
    "            lw=2,\n",
    "            # label=f'{label}\\n(Avg AUC = {np.mean(aucs):.2f} ± {np.std(aucs):.2f})',\n",
    "            label=label,\n",
    "            color=color,\n",
    "            ls=ls,\n",
    "        )\n",
    "        ax.fill_between(fpr_grid, lo_tpr, hi_tpr, alpha=0.2, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve_panel(get_result_paths, figname=\"ROC_curves_all-viral_predictions\", skip_deepseek=False):\n",
    "    fig, axs = plt.subplots(figsize=(13, 13), ncols=2, nrows=2)\n",
    "    fontsize = 16\n",
    "\n",
    "    # Flatten axs for easier indexing, but keep 2x2 structure for barplot\n",
    "    axs_flat = axs.flatten()\n",
    "\n",
    "    # We'll collect AUCs for all (model, path) combinations for the barplot\n",
    "    auc_barplot_entries = []  # List of dicts: {'model': ..., 'path': ..., 'auc_mean': ..., 'auc_std': ..., 'n_runs': ..., 'color': ..., 'hatch': ...}\n",
    "\n",
    "    col_row_idx = 0\n",
    "    for color, model in zip(main_colors, models):\n",
    "\n",
    "        aucs_for_model = []\n",
    "\n",
    "        if model == \"Random Forest\":\n",
    "            y_scores = []\n",
    "            aucs_rf = []\n",
    "            for i, seed in enumerate([\"\", \"_02\", \"_03\"]):\n",
    "                path_to_pkl = f\"{train_test_data_folder}/X_test_{pathogen}_rf{seed}.pkl\"\n",
    "                with open(path_to_pkl, \"rb\") as f:\n",
    "                    pred_df = pickle.load(f)\n",
    "\n",
    "                y_score_list = pred_df['probability_of_viral_rf']\n",
    "                y_scores.append(y_score_list)\n",
    "\n",
    "                auc_val = roc_auc_score(Y_TRUE, y_score_list)\n",
    "                aucs_rf.append(auc_val)\n",
    "                aucs_for_model.append(auc_val)\n",
    "\n",
    "            label = model\n",
    "\n",
    "            for ax in axs_flat:\n",
    "                plot_roc_curve(Y_TRUE, y_scores, ax, color=color, label=label)\n",
    "\n",
    "            # For barplot: aggregate across seeds/runs\n",
    "            auc_barplot_entries.append({\n",
    "                'model': model,\n",
    "                'path': \"RF\",\n",
    "                'auc_mean': np.mean(aucs_rf),\n",
    "                'auc_std': np.std(aucs_rf, ddof=1) if len(aucs_rf) > 1 else 0,\n",
    "                'n_runs': len(aucs_rf),\n",
    "                'color': color,\n",
    "                'hatch': None\n",
    "            })\n",
    "\n",
    "        elif model == \"RAG\":\n",
    "            path_to_pkl = f\"{train_test_data_folder}/X_test_{pathogen}_rag.pkl\"\n",
    "            pred_df = pd.read_pickle(path_to_pkl)\n",
    "\n",
    "            y_scores_weighted = pred_df['weighted_averages']\n",
    "            label = rag_label\n",
    "            for ax in axs_flat:\n",
    "                plot_roc_curve(Y_TRUE, y_scores_weighted, ax, color=color, label=label)\n",
    "\n",
    "            auc_val = roc_auc_score(Y_TRUE, y_scores_weighted)\n",
    "            auc_barplot_entries.append({\n",
    "                'model': model,\n",
    "                'path': rag_label,\n",
    "                'auc_mean': auc_val,\n",
    "                'auc_std': 0,\n",
    "                'n_runs': 1,\n",
    "                'color': color,\n",
    "                'hatch': None\n",
    "            })\n",
    "            aucs_for_model.append(auc_val)\n",
    "\n",
    "        else:\n",
    "            paths = get_result_paths(model)\n",
    "            path_shades = get_shades(color, n=len(paths)-1)\n",
    "            for i, path in enumerate(paths):\n",
    "\n",
    "                if skip_deepseek:\n",
    "                    if \"deepseek\" in model or \"llama\" in model:\n",
    "                        continue\n",
    "\n",
    "                if \"deepseek\" in model and \"_rf\" in path:\n",
    "                    continue\n",
    "\n",
    "                y_scores = []\n",
    "                y_trues = []\n",
    "                aucs_this_path = []\n",
    "                for run_id in [1, 2, 3]:\n",
    "                    path_to_csv = f\"{path}/{model}_run0{str(run_id)}_predictions.csv\"\n",
    "                    if not os.path.exists(path_to_csv):\n",
    "                        continue\n",
    "                    pred_df = pd.read_csv(path_to_csv)\n",
    "\n",
    "                    y_score_list = pred_df['probability_of_viral']\n",
    "                    if len(y_score_list) != len(Y_TRUE):\n",
    "                        continue\n",
    "\n",
    "                    # Replace missing predictions (NaN or 'unknown') with 0  !!! Is this a good way to handle this??\n",
    "                    nan_count = y_score_list.isna().sum()\n",
    "                    unknown_count = (y_score_list == 'unknown').sum()\n",
    "                    if nan_count > 0 or unknown_count > 0:\n",
    "                        if nan_count > 0:\n",
    "                            print(f\"WARNING: {nan_count} NaN values found in 'probability_of_viral' for {path_to_csv}\")\n",
    "                        if unknown_count > 0:\n",
    "                            print(f\"WARNING: {unknown_count} 'unknown' values found in 'probability_of_viral' for {path_to_csv}\")\n",
    "                        \n",
    "                        # Remove missing/unknown/nan values from y_score_list and remove the same indices from y_true\n",
    "                        mask = ~(y_score_list.isna() | (y_score_list == 'unknown'))\n",
    "                        y_score_list = y_score_list[mask].astype(float)\n",
    "                        y_true_filtered = np.array(Y_TRUE)[mask.values] if isinstance(Y_TRUE, (list, np.ndarray)) else Y_TRUE[mask]\n",
    "                    else:\n",
    "                        y_true_filtered = Y_TRUE.copy()\n",
    "\n",
    "                    y_trues.append(y_true_filtered)\n",
    "                    y_scores.append(y_score_list)\n",
    "\n",
    "                    # Compute AUC for this run\n",
    "                    try:\n",
    "                        auc_val = roc_auc_score(y_true_filtered, y_score_list)\n",
    "                        aucs_this_path.append(auc_val)\n",
    "                        aucs_for_model.append(auc_val)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "                knowledge_type = path.split(\"/\")[-1]\n",
    "                label = f\"{k_naming_dict[knowledge_type]}\"\n",
    "\n",
    "                if len(y_scores) == 0:\n",
    "                    continue\n",
    "                elif len(y_scores) == 1:\n",
    "                    y_scores = y_scores[0]\n",
    "                if len(y_trues) == 1:\n",
    "                    y_trues = y_trues[0]\n",
    "\n",
    "                if \"rag\" in path:\n",
    "                    ls = \"--\"\n",
    "                    color_to_use = path_shades[i-1]\n",
    "                else:\n",
    "                    ls = None\n",
    "                    color_to_use = path_shades[i]\n",
    "\n",
    "                ax = axs_flat[col_row_idx]\n",
    "                ax.set_title(model, fontsize=fontsize+2, fontweight=\"bold\", color=color_to_use)\n",
    "                plot_roc_curve(y_trues, y_scores, ax, color=color_to_use, label=label, ls=ls)\n",
    "\n",
    "                # For barplot: aggregate across runs for this (model, path)\n",
    "                if len(aucs_this_path) > 0:\n",
    "                    auc_barplot_entries.append({\n",
    "                        'model': model,\n",
    "                        'path': f\"{k_naming_dict[knowledge_type]}\",\n",
    "                        'auc_mean': np.mean(aucs_this_path),\n",
    "                        'auc_std': np.std(aucs_this_path, ddof=1) if len(aucs_this_path) > 1 else 0,\n",
    "                        'n_runs': len(aucs_this_path),\n",
    "                        'color': color_to_use,\n",
    "                        'hatch': \"/\" if \"rag\" in path else None\n",
    "                    })\n",
    "\n",
    "            col_row_idx += 1\n",
    "\n",
    "    # Add diagonal line and formatting to ROC subplots (first 3)\n",
    "    for ax in axs_flat:\n",
    "        ax.plot([0, 1], [0, 1], color='lightgrey', linestyle='-', label='Random guess', lw=2)\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.02])\n",
    "        ax.legend(loc='lower right', fontsize=fontsize)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "        ax.grid(True, color='grey', linestyle='--', linewidth=0.7, alpha=0.5)\n",
    "        ax.set_axisbelow(True)\n",
    "        # ax.set_ylabel(\"True Positive Rate\", fontsize=fontsize+2)\n",
    "        # ax.set_xlabel(\"False Positive Rate\", fontsize=fontsize+2)\n",
    "\n",
    "    fig.text(0.5, -0.01, 'False Positive Rate', ha='center', va='center', fontsize=fontsize+4)\n",
    "    fig.text(-0.01, 0.5, 'True Positive Rate', ha='center', va='center', rotation='vertical', fontsize=fontsize+4)\n",
    "\n",
    "\n",
    "    # ## Barplot of AUCs for all (model, path) combinations in the last subplot (bottom right)\n",
    "    # ax_bar = axs_flat[3]\n",
    "\n",
    "    # # Prepare barplot data\n",
    "    # bar_labels = []\n",
    "    # bar_aucs = []\n",
    "    # bar_stds = []\n",
    "    # bar_colors = []\n",
    "    # bar_hatches = []\n",
    "    # for entry in auc_barplot_entries:\n",
    "    #     if entry['model'] == \"Random Forest\":\n",
    "    #         bar_labels.append(entry['model'])\n",
    "    #     else:\n",
    "    #         bar_labels.append(entry['path'])\n",
    "    #     bar_aucs.append(entry['auc_mean'])\n",
    "    #     bar_stds.append(entry['auc_std'])\n",
    "    #     bar_colors.append(entry['color'])\n",
    "    #     bar_hatches.append(entry.get('hatch', None))\n",
    "\n",
    "    # bar_positions = np.arange(len(bar_labels))\n",
    "    # bars = ax_bar.bar(bar_positions, bar_aucs, color=bar_colors, alpha=0.7, yerr=bar_stds, capsize=5)\n",
    "\n",
    "    # # Set hatch for RAG bar\n",
    "    # for bar, hatch in zip(bars, bar_hatches):\n",
    "    #     if hatch is not None:\n",
    "    #         bar.set_hatch(hatch)\n",
    "\n",
    "    # # Add numbers above the bars\n",
    "    # for idx, (bar, auc, std) in enumerate(zip(bars, bar_aucs, bar_stds)):\n",
    "    #     height = bar.get_height() + std if std > 0 else bar.get_height()\n",
    "    #     # Format: mean ± std, but only show std if > 0\n",
    "    #     # if std > 0:\n",
    "    #     #     label_text = f\"{auc:.2f}±{std:.2f}\"\n",
    "    #     # else:\n",
    "    #     label_text = f\"{auc:.2f}\"\n",
    "    #     ax_bar.text(\n",
    "    #         bar.get_x() + bar.get_width() / 2,\n",
    "    #         height + 0.01,\n",
    "    #         label_text,\n",
    "    #         ha='center',\n",
    "    #         va='bottom',\n",
    "    #         fontsize=fontsize-2\n",
    "    #     )\n",
    "\n",
    "    # ax_bar.axhline(0.5, color='lightgrey', linestyle='-', lw=2)\n",
    "    # ax_bar.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "    # ax_bar.set_xticks(bar_positions)\n",
    "    # ax_bar.set_xticklabels(bar_labels, rotation=45, ha='right', fontsize=fontsize-1)\n",
    "    # ax_bar.set_ylabel(\"AUC\", fontsize=fontsize+2)\n",
    "    # # ax_bar.set_title(\"Area Under the Curve (AUC)\", fontsize=fontsize+2)\n",
    "    # ax_bar.set_ylim(0, 1)\n",
    "    # ax_bar.grid(True, axis='y', color='grey', linestyle='--', linewidth=0.7, alpha=0.5)\n",
    "    # ax_bar.set_axisbelow(True)\n",
    "    # ax_bar.margins(x=0.02)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(f\"figures/{figname}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    return auc_barplot_entries\n",
    "\n",
    "auc_barplot_entries = plot_roc_curve_panel(get_result_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907a75a",
   "metadata": {},
   "source": [
    "Same but for natural language models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_roc_curve_panel(get_result_paths_supp, figname=\"ROC_curves_all-viral_predictions_json2text\", skip_deepseek=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b7718",
   "metadata": {},
   "source": [
    "# Plot accuracy, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute accuracy, sensitivity, specificity for binary classification.\"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    # Convert predicted labels to 1/0\n",
    "    y_pred_bin = np.array([1 if x == \"yes\" else 0 for x in y_pred])\n",
    "    # Accuracy\n",
    "    acc = np.mean(y_pred_bin == y_true)\n",
    "    # Sensitivity (Recall, True Positive Rate)\n",
    "    if np.sum(y_true == 1) > 0:\n",
    "        sens = np.sum((y_pred_bin == 1) & (y_true == 1)) / np.sum(y_true == 1)\n",
    "    else:\n",
    "        sens = np.nan\n",
    "    # Specificity (True Negative Rate)\n",
    "    if np.sum(y_true == 0) > 0:\n",
    "        spec = np.sum((y_pred_bin == 0) & (y_true == 0)) / np.sum(y_true == 0)\n",
    "    else:\n",
    "        spec = np.nan\n",
    "    return acc, sens, spec\n",
    "\n",
    "def mean_std(values):\n",
    "    \"\"\"Compute mean and standard deviation for a list of values.\"\"\"\n",
    "    arr = np.array(values)\n",
    "    mean = np.nanmean(arr)\n",
    "    std = np.nanstd(arr, ddof=1)\n",
    "    return mean, std\n",
    "\n",
    "def plot_metrics_with_std(y_trues, y_labels, axes, x_idx, color, fontsize=12, hatch=None):\n",
    "    accs, senss, specs = [], [], []\n",
    "    for trues, preds in zip(y_trues, y_labels):\n",
    "        acc, sens, spec = compute_metrics(trues, preds)\n",
    "        accs.append(acc)\n",
    "        senss.append(sens)\n",
    "        specs.append(spec)\n",
    "    metrics = [accs, senss, specs]\n",
    "    metric_names = [\"Accuracy\", \"Sensitivity\", \"Specificity\"]\n",
    "\n",
    "    bw = 0.7\n",
    "    for i, (vals, ax) in enumerate(zip(metrics, axes)):\n",
    "        mean, std = mean_std(vals)\n",
    "        ax.bar([x_idx], [mean], yerr=[[std], [std]], color=color, alpha=0.8, capsize=4, width=bw, hatch=hatch)\n",
    "        ax.set_ylim(0, 1)\n",
    "        # ax.set_xticks([0])\n",
    "        ax.set_ylabel(metric_names[i], fontsize=fontsize+2)\n",
    "        # ax.set_title(f\"{metric_names[i]} (mean ± std)\", fontsize=fontsize)\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "        ax.margins(x=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a736e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs_all = plt.subplots(figsize=(10, 13), nrows=4, sharex=True)\n",
    "fontsize = 16\n",
    "\n",
    "x_idx = 0\n",
    "xticklabels = []\n",
    "xtick_positions = []\n",
    "\n",
    "# Helper to add numbers above bars\n",
    "def annotate_bars(ax, xpos, mean, std, fontsize=10):\n",
    "    \"\"\"Annotate a single bar at xpos with mean ± std.\"\"\"\n",
    "    # Find the bar (there should be only one at xpos)\n",
    "    for bar in ax.patches:\n",
    "        # bar.get_x() is left edge, bar.get_width() is width\n",
    "        if abs(bar.get_x() + bar.get_width()/2 - xpos) < 1e-6:\n",
    "            height = bar.get_height()\n",
    "            # ax.annotate(f\"{mean:.2f}±{std:.2f}\", \n",
    "            ax.annotate(f\"{mean:.2f}\", \n",
    "                        xy=(bar.get_x() + bar.get_width()/2, height + std if not np.isnan(std) else height),\n",
    "                        xytext=(0, 2),  # 2 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontsize=fontsize)\n",
    "            break\n",
    "\n",
    "\n",
    "## Barplot of AUCs for all (model, path) combinations\n",
    "ax_bar = axs_all[0]\n",
    "\n",
    "# Prepare barplot data\n",
    "bar_labels = []\n",
    "bar_aucs = []\n",
    "bar_stds = []\n",
    "bar_colors = []\n",
    "bar_hatches = []\n",
    "for entry in auc_barplot_entries:\n",
    "    if entry['model'] == \"Random Forest\":\n",
    "        bar_labels.append(entry['model'])\n",
    "    else:\n",
    "        bar_labels.append(entry['path'])\n",
    "    bar_aucs.append(entry['auc_mean'])\n",
    "    bar_stds.append(entry['auc_std'])\n",
    "    bar_colors.append(entry['color'])\n",
    "    bar_hatches.append(entry.get('hatch', None))\n",
    "\n",
    "bar_positions = np.arange(len(bar_labels))\n",
    "bars = ax_bar.bar(bar_positions, bar_aucs, color=bar_colors, alpha=0.7, yerr=bar_stds, capsize=5)\n",
    "\n",
    "# Set hatch for RAG bar\n",
    "for bar, hatch in zip(bars, bar_hatches):\n",
    "    if hatch is not None:\n",
    "        bar.set_hatch(hatch)\n",
    "\n",
    "# Add numbers above the bars\n",
    "for idx, (bar, auc, std) in enumerate(zip(bars, bar_aucs, bar_stds)):\n",
    "    height = bar.get_height() + std if std > 0 else bar.get_height()\n",
    "    # Format: mean ± std, but only show std if > 0\n",
    "    # if std > 0:\n",
    "    #     label_text = f\"{auc:.2f}±{std:.2f}\"\n",
    "    # else:\n",
    "    label_text = f\"{auc:.2f}\"\n",
    "    ax_bar.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + 0.01,\n",
    "        label_text,\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=fontsize-4\n",
    "    )\n",
    "\n",
    "ax_bar.axhline(0.5, color='lightgrey', linestyle='-', lw=2)\n",
    "ax_bar.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "ax_bar.set_xticks(bar_positions)\n",
    "ax_bar.set_xticklabels(bar_labels, rotation=45, ha='right', fontsize=fontsize-1)\n",
    "ax_bar.set_ylabel(\"AUC\", fontsize=fontsize+2, fontweight=\"bold\")\n",
    "# ax_bar.set_title(\"Area Under the Curve (AUC)\", fontsize=fontsize+2)\n",
    "ax_bar.set_ylim(0, 1)\n",
    "ax_bar.grid(True, axis='y', color='grey', linestyle='--', linewidth=0.7, alpha=0.5)\n",
    "ax_bar.set_axisbelow(True)\n",
    "ax_bar.margins(x=0.02)\n",
    "\n",
    "\n",
    "## Plot acc, sens, spec\n",
    "axs = axs_all[1:]\n",
    "for color, model in zip(main_colors, models):\n",
    "\n",
    "    if model == \"Random Forest\":\n",
    "        y_labels = []\n",
    "        for seed in [\"\", \"_02\", \"_03\"]:\n",
    "            path_to_pkl = f\"{train_test_data_folder}/X_test_{pathogen}_rf{seed}.pkl\"\n",
    "            with open(path_to_pkl, \"rb\") as f:\n",
    "                pred_df = pickle.load(f)\n",
    "\n",
    "            y_score_list = pred_df['viral_rf']\n",
    "            y_labels.append(y_score_list)\n",
    "\n",
    "        xticklabels.append(model)\n",
    "        xtick_positions.append(x_idx)\n",
    "        # Compute metrics for annotation\n",
    "        accs, senss, specs = [], [], []\n",
    "        for trues, preds in zip([Y_TRUE for _ in range(len(y_labels))], y_labels):\n",
    "            acc, sens, spec = compute_metrics(trues, preds)\n",
    "            accs.append(acc)\n",
    "            senss.append(sens)\n",
    "            specs.append(spec)\n",
    "        metrics = [accs, senss, specs]\n",
    "        for i, (vals, ax) in enumerate(zip(metrics, axs)):\n",
    "            mean, std = mean_std(vals)\n",
    "            ax.bar([x_idx], [mean], yerr=[[std], [std]], color=color, alpha=0.8, capsize=4, width=0.7)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.set_ylabel([\"Accuracy\", \"Sensitivity\", \"Specificity\"][i], fontsize=fontsize+2)\n",
    "            ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "            ax.set_axisbelow(True)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "            ax.margins(x=0.02)\n",
    "            annotate_bars(ax, x_idx, mean, std, fontsize=fontsize-4)\n",
    "        x_idx += 1\n",
    "\n",
    "    elif model == \"RAG\":\n",
    "        path_to_pkl = f\"{train_test_data_folder}/X_test_{pathogen}_rag.pkl\"\n",
    "        pred_df = pd.read_pickle(path_to_pkl)\n",
    "\n",
    "        # y_labels = pred_df['averages_round'].map({0: \"no\", 1: \"yes\"})\n",
    "        y_labels = pred_df['weighted_averages_round'].map({0: \"no\", 1: \"yes\"})\n",
    "\n",
    "        # Compute metrics for annotation\n",
    "        accs, senss, specs = [], [], []\n",
    "        acc, sens, spec = compute_metrics(Y_TRUE, y_labels)\n",
    "        accs.append(acc)\n",
    "        senss.append(sens)\n",
    "        specs.append(spec)\n",
    "        metrics = [accs, senss, specs]\n",
    "        for i, (vals, ax) in enumerate(zip(metrics, axs)):\n",
    "            mean, std = mean_std(vals)\n",
    "            ax.bar([x_idx], [mean], yerr=[[std], [std]], color=color, alpha=0.8, capsize=4, width=0.7)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.set_ylabel([\"Accuracy\", \"Sensitivity\", \"Specificity\"][i], fontsize=fontsize+2)\n",
    "            ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "            ax.set_axisbelow(True)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "            ax.margins(x=0.02)\n",
    "            annotate_bars(ax, x_idx, mean, std, fontsize=fontsize-4)\n",
    "        xticklabels.append(rag_label)\n",
    "        xtick_positions.append(x_idx)\n",
    "        x_idx += 1\n",
    "\n",
    "    else:\n",
    "        paths = get_result_paths(model)\n",
    "        path_shades = get_shades(color, n=len(paths)-1)\n",
    "        for i, path in enumerate(paths):\n",
    "\n",
    "            if \"deepseek\" in model and \"_rf\" in path:\n",
    "                continue\n",
    "\n",
    "            y_scores = []\n",
    "            y_trues = []\n",
    "            for run_id in [1, 2, 3]:\n",
    "                path_to_csv = f\"{path}/{model}_run0{str(run_id)}_predictions.csv\"\n",
    "                if not os.path.exists(path_to_csv):\n",
    "                    continue\n",
    "                pred_df = pd.read_csv(path_to_csv)\n",
    "\n",
    "                y_score_list = pred_df['viral']\n",
    "                if len(y_score_list) != len(Y_TRUE):\n",
    "                    continue\n",
    "\n",
    "                # Replace missing predictions (NaN or 'unknown') with 0  !!! Is this a good way to handle this??\n",
    "                nan_count = y_score_list.isna().sum()\n",
    "                unknown_count = (y_score_list == 'unknown').sum()\n",
    "                if nan_count > 0 or unknown_count > 0:\n",
    "                    if nan_count > 0:\n",
    "                        print(f\"WARNING: {nan_count} NaN values found in 'viral' for {path_to_csv}\")\n",
    "                    if unknown_count > 0:\n",
    "                        print(f\"WARNING: {unknown_count} 'unknown' values found in 'viral' for {path_to_csv}\")\n",
    "                    \n",
    "                    # Remove missing/unknown/nan values from y_score_list and remove the same indices from y_true\n",
    "                    mask = ~(y_score_list.isna() | (y_score_list == 'unknown'))\n",
    "                    y_score_list = y_score_list[mask].astype(str)\n",
    "                    y_true_filtered = np.array(Y_TRUE)[mask.values] if isinstance(Y_TRUE, (list, np.ndarray)) else Y_TRUE[mask]\n",
    "                else:\n",
    "                    y_true_filtered = Y_TRUE.copy()\n",
    "\n",
    "                y_trues.append(y_true_filtered)\n",
    "                y_scores.append(y_score_list)\n",
    "\n",
    "            knowledge_type = path.split(\"/\")[-1]\n",
    "            # label = f\"{model}\\n({k_naming_dict[knowledge_type]})\"\n",
    "            label = k_naming_dict[knowledge_type]\n",
    "\n",
    "            if len(y_scores) == 0:\n",
    "                continue\n",
    "\n",
    "            if \"rag\" in path:\n",
    "                hatch = \"/\"\n",
    "                color = path_shades[i-1]\n",
    "            else:\n",
    "                hatch = None\n",
    "                color = path_shades[i]\n",
    "\n",
    "            # Compute metrics for annotation\n",
    "            accs, senss, specs = [], [], []\n",
    "            for trues, preds in zip(y_trues, y_scores):\n",
    "                acc, sens, spec = compute_metrics(trues, preds)\n",
    "                accs.append(acc)\n",
    "                senss.append(sens)\n",
    "                specs.append(spec)\n",
    "            metrics = [accs, senss, specs]\n",
    "            for j, (vals, ax) in enumerate(zip(metrics, axs)):\n",
    "                mean, std = mean_std(vals)\n",
    "                ax.bar([x_idx], [mean], yerr=[[std], [std]], color=color, alpha=0.8, capsize=4, width=0.7, hatch=hatch)\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_ylabel([\"Accuracy\", \"Sensitivity\", \"Specificity\"][j], fontsize=fontsize+2, fontweight=\"bold\")\n",
    "                ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "                ax.set_axisbelow(True)\n",
    "                ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "                ax.margins(x=0.02)\n",
    "                annotate_bars(ax, x_idx, mean, std, fontsize=fontsize-4)\n",
    "            xticklabels.append(label)\n",
    "            xtick_positions.append(x_idx)\n",
    "            x_idx += 1\n",
    "\n",
    "for ax in axs_all:\n",
    "    ax.set_ylim(0, 1.05)\n",
    "\n",
    "# Set both the tick positions and the labels to ensure all are shown and aligned\n",
    "axs[-1].set_xticks(xtick_positions)\n",
    "axs[-1].set_xticklabels(xticklabels, rotation=45, ha=\"right\")\n",
    "\n",
    "axs[0].axhline(y=0.5, color='lightgray', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(\"figures/acc_sens_spec_all-viral_predictions.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375a2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "908df2bf",
   "metadata": {},
   "source": [
    "# Plot breakdown of pos / neg and pathogens in test/train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd6c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = f\"{train_test_data_folder}/X_test_{pathogen}_rf.pkl\"\n",
    "test_df2 = pd.read_pickle(test_data_path)\n",
    "\n",
    "train_data_path = f\"{train_test_data_folder}/X_train_{pathogen}_rf.pkl\"\n",
    "train_df = pd.read_pickle(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2187f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pathogen labels to train and test data\n",
    "label_cols = [col for col in data_df.columns if col.endswith('_label')]\n",
    "cols_to_keep = ['record_id'] + label_cols\n",
    "\n",
    "test_df_labels = test_df2.merge(data_df[cols_to_keep], on='record_id', how='left')\n",
    "train_df_labels = train_df.merge(data_df[cols_to_keep], on='record_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc62f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_value_counts(df, title_suffix=\"Test Set\"):\n",
    "    \"\"\"\n",
    "    Plots the value counts for all *_label columns in the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing *_label columns\n",
    "    - title_suffix: str, suffix to add to the plot title (e.g., 'Test Set' or 'Train Set')\n",
    "    \"\"\"\n",
    "    label_cols = [col for col in df.columns if col.endswith('_label')]\n",
    "\n",
    "    # For each label, get counts for 0, 1, 2 (or whatever unique values exist)\n",
    "    label_value_counts = {}\n",
    "    all_possible_values = set()\n",
    "    for col in label_cols:\n",
    "        # Get all unique values (including NaN)\n",
    "        values = df[col].value_counts(dropna=False).sort_index()\n",
    "        # Convert NaN to string for plotting\n",
    "        values.index = values.index.map(\n",
    "            lambda x: str(int(x)) if pd.notnull(x) and isinstance(x, (int, float)) and float(x).is_integer() else str(x)\n",
    "        )\n",
    "        label_value_counts[col] = values\n",
    "        all_possible_values.update(values.index)\n",
    "\n",
    "    # Sort the possible values for consistent bar order\n",
    "    all_possible_values = sorted(all_possible_values, key=lambda x: (x == 'nan', x))\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    bar_width = 0.2\n",
    "    x = np.arange(len(label_cols))  # label positions\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(8, len(label_cols)*0.8), 6))\n",
    "\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # Add more if needed\n",
    "\n",
    "    for i, val in enumerate(all_possible_values):\n",
    "        counts = []\n",
    "        for col in label_cols:\n",
    "            # Get count for this value, or 0 if not present\n",
    "            counts.append(label_value_counts[col].get(val, 0))\n",
    "        ax.bar(\n",
    "            x + (i - (len(all_possible_values)-1)/2)*bar_width,\n",
    "            counts,\n",
    "            width=bar_width,\n",
    "            label=f\"Label {val}\",\n",
    "            color=colors[i % len(colors)]\n",
    "        )\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(label_cols, rotation=45, ha='right')\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(f\"Label Value Counts per *_label Column ({title_suffix})\")\n",
    "    ax.legend(title=\"Label Value\")\n",
    "\n",
    "    # Add value labels on top of bars\n",
    "    for i, val in enumerate(all_possible_values):\n",
    "        for j, col in enumerate(label_cols):\n",
    "            count = label_value_counts[col].get(val, 0)\n",
    "            # Find a reasonable offset for the text\n",
    "            offset = max(1, 0.01*max(label_value_counts[col].values)) if len(label_value_counts[col].values) > 0 else 1\n",
    "            ax.text(\n",
    "                j + (i - (len(all_possible_values)-1)/2)*bar_width,\n",
    "                count + offset,\n",
    "                str(int(count)),\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=8\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_label_value_counts(test_df_labels, title_suffix=\"Test Set\")\n",
    "plot_label_value_counts(train_df_labels, title_suffix=\"Train Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_viral_label_bar(test_df, train_df, fontsize=10):\n",
    "    \"\"\"\n",
    "    Plots a grouped bar plot showing the counts of all-viral_label==1 and all-viral_label==0\n",
    "    for train and test data, with 'train' and 'test' on the x-axis and all-viral_label as the legend.\n",
    "    For all-viral_label==0, the bar is further broken down (stacked) by Malaria_label==0 and Malaria_label==1.\n",
    "\n",
    "    Parameters:\n",
    "    - test_df: pandas DataFrame for test data, must contain 'all-viral_label' and 'Malaria_label'\n",
    "    - train_df: pandas DataFrame for train data, must contain 'all-viral_label' and 'Malaria_label'\n",
    "    - fontsize: int, controls the fontsize of the title, axes labels, and ticklabels\n",
    "    \"\"\"\n",
    "\n",
    "    # Helper to get counts for all-viral_label==0 split by Malaria_label\n",
    "    def get_nonviral_malaria_counts(df):\n",
    "        nonviral = df[df['all-viral_label'] == 0]\n",
    "        malaria_counts = nonviral['Malaria_label'].value_counts().sort_index()\n",
    "        # Ensure both 0 and 1 are present\n",
    "        return [malaria_counts.get(0, 0), malaria_counts.get(1, 0)]\n",
    "\n",
    "    # Get counts for all-viral_label==1\n",
    "    train_viral = train_df['all-viral_label'].value_counts().get(1, 0)\n",
    "    test_viral = test_df['all-viral_label'].value_counts().get(1, 0)\n",
    "\n",
    "    # Get counts for all-viral_label==0, split by Malaria_label\n",
    "    train_nonviral_malaria = get_nonviral_malaria_counts(train_df)\n",
    "    test_nonviral_malaria = get_nonviral_malaria_counts(test_df)\n",
    "\n",
    "    bar_width = 0.4\n",
    "    x = np.arange(2)  # 0: train, 1: test\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "    # Stacked bars for all-viral_label==0 (Malaria_label==0 and ==1)\n",
    "    colors_nonviral = ['grey', 'lightgrey']\n",
    "    bars_nonviral_0 = [train_nonviral_malaria[0], test_nonviral_malaria[0]]\n",
    "    bars_nonviral_1 = [train_nonviral_malaria[1], test_nonviral_malaria[1]]\n",
    "\n",
    "    p1 = ax.bar(x, bars_nonviral_0, width=bar_width, label=\"Non-viral\", color=colors_nonviral[0])\n",
    "    p2 = ax.bar(x, bars_nonviral_1, width=bar_width, bottom=bars_nonviral_0, label=\"Non-viral (Malaria)\", color=colors_nonviral[1])\n",
    "\n",
    "    # Bar for all-viral_label==1\n",
    "    color_viral = \"#FF0000\"\n",
    "    bars_viral = [train_viral, test_viral]\n",
    "    p3 = ax.bar(x + bar_width, bars_viral, width=bar_width, label=\"Viral\", color=color_viral)\n",
    "\n",
    "    # Add value labels\n",
    "    for i in range(2):\n",
    "        # Non-viral, Malaria=0\n",
    "        offset = max(1, 0.001 * max(bars_nonviral_0 + bars_nonviral_1 + bars_viral))\n",
    "        if bars_nonviral_0[i] > 0:\n",
    "            ax.text(x[i], bars_nonviral_0[i] / 2, str(bars_nonviral_0[i]), ha='center', va='center', fontsize=fontsize, color='black')\n",
    "        # Non-viral, Malaria=1\n",
    "        if bars_nonviral_1[i] > 0:\n",
    "            ax.text(x[i], bars_nonviral_0[i] + bars_nonviral_1[i] / 2, str(bars_nonviral_1[i]), ha='center', va='center', fontsize=fontsize, color='black')\n",
    "        # Viral\n",
    "        if bars_viral[i] > 0:\n",
    "            ax.text(x[i] + bar_width, bars_viral[i] / 2, str(bars_viral[i]), ha='center', va='center', fontsize=fontsize, color='black')\n",
    "\n",
    "    ax.set_xticks(x + bar_width / 2)\n",
    "    ax.set_xticklabels(['Training Data', 'Testing Data'], fontsize=fontsize)\n",
    "    ax.set_ylabel(\"Count\", fontsize=fontsize)\n",
    "    ax.set_title(\"Viral vs Non-viral Counts in the Training and Testing Data\", fontsize=fontsize, fontweight=\"bold\")\n",
    "    ax.legend(loc=\"upper center\", fontsize=fontsize)\n",
    "\n",
    "    # Set yticklabels fontsize\n",
    "    ax.tick_params(axis='y', labelsize=fontsize)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figures/train_test_data_viral_breakdown.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "plot_all_viral_label_bar(test_df_labels, train_df_labels, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd423d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: GPT-4, version 2024-06-13\n",
    "\n",
    "def plot_label_upset_and_malaria_bar(df, title_suffix=\"Test Set\", fontsize=12):\n",
    "    \"\"\"\n",
    "    For a given DataFrame, creates:\n",
    "    - An UpSet plot for rows where all-viral_label == 1, showing (co-)occurrences of *_label columns == 1 (excluding 'all-viral_label').\n",
    "    - For rows where all-viral_label == 0, plots a bar plot showing counts for Malaria_label==0 versus Malaria_label==1,\n",
    "      and confirms that no other *_label column is == 1 in these rows.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing *_label columns\n",
    "    - title_suffix: str, suffix to add to the plot title (e.g., 'Test Set' or 'Train Set')\n",
    "    - fontsize: int, controls the fontsize of the title, axes labels, and ticklabels\n",
    "    \"\"\"\n",
    "\n",
    "    # Select *_label columns, excluding 'all-viral_label'\n",
    "    all_label_cols = [col for col in df.columns if col.endswith('_label') and col != 'all-viral_label']\n",
    "\n",
    "    # Split the dataframe by all-viral_label\n",
    "    for_viral = df[df['all-viral_label'] == 1]\n",
    "    for_nonviral = df[df['all-viral_label'] == 0]\n",
    "\n",
    "    # --- UpSet plot for all-viral_label == 1 ---\n",
    "    def get_nonzero_label_cols(subset_df, label_cols):\n",
    "        # Only keep *_label columns that have at least one value == 1\n",
    "        nonzero_cols = [col for col in label_cols if subset_df[col].eq(1).any()]\n",
    "        return nonzero_cols\n",
    "\n",
    "    viral_label_cols = get_nonzero_label_cols(for_viral, all_label_cols)\n",
    "    label_bool_viral = for_viral[viral_label_cols] == 1 if viral_label_cols else pd.DataFrame()\n",
    "    label_bool_viral = label_bool_viral.fillna(False)\n",
    "\n",
    "    def bool_df_to_upset_series(bool_df, label_cols):\n",
    "        if bool_df.empty:\n",
    "            return None\n",
    "        from collections import Counter\n",
    "        if len(label_cols) == 1:\n",
    "            # Series with index True/False\n",
    "            counts = Counter(bool_df.iloc[:, 0])\n",
    "            s = pd.Series([counts.get(True, 0), counts.get(False, 0)], index=[True, False], name=label_cols[0])\n",
    "            # Only keep True if there are any\n",
    "            s = s[s.index == True]\n",
    "            return s if not s.empty else None\n",
    "        else:\n",
    "            tuples = [tuple(row) for row in bool_df.values]\n",
    "            counts = Counter(tuples)\n",
    "            index = pd.MultiIndex.from_tuples(counts.keys(), names=label_cols)\n",
    "            s = pd.Series(list(counts.values()), index=index)\n",
    "            return s if not s.empty else None\n",
    "\n",
    "    upset_data_viral = bool_df_to_upset_series(label_bool_viral, viral_label_cols) if not for_viral.empty and viral_label_cols else None\n",
    "\n",
    "    def is_upset_compatible(series):\n",
    "        if series is None or series.empty:\n",
    "            return False\n",
    "        idx = series.index\n",
    "        if isinstance(idx, pd.MultiIndex):\n",
    "            return idx.nlevels > 0\n",
    "        elif isinstance(idx, pd.Index):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # Plot for all-viral_label == 1\n",
    "    if (\n",
    "        upset_data_viral is not None\n",
    "        and not label_bool_viral.empty\n",
    "        and label_bool_viral.sum(axis=1).max() > 0\n",
    "        and is_upset_compatible(upset_data_viral)\n",
    "    ):\n",
    "        try:\n",
    "            upset_viral = UpSet(upset_data_viral, show_counts=True, sort_by='cardinality')\n",
    "            upset_viral.plot()\n",
    "            plt.title(f\"{title_suffix} (Viral)\", fontsize=fontsize+2, fontweight=\"bold\")\n",
    "            # Set ticklabel font sizes for all axes in the UpSet plot\n",
    "            for ax in plt.gcf().axes:\n",
    "                ax.tick_params(axis='both', labelsize=fontsize)\n",
    "                # Set axes label font sizes if present\n",
    "                if ax.get_xlabel():\n",
    "                    ax.set_xlabel(ax.get_xlabel(), fontsize=fontsize)\n",
    "                if ax.get_ylabel():\n",
    "                    ax.set_ylabel(ax.get_ylabel(), fontsize=fontsize)\n",
    "                # Remove \"_label\" from y axis ticklabels\n",
    "                yticklabels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "                if any(\"_label\" in label for label in yticklabels):\n",
    "                    new_yticklabels = [label.replace(\"_label\", \"\") for label in yticklabels]\n",
    "                    ax.set_yticklabels(new_yticklabels, fontsize=fontsize)\n",
    "            plt.savefig(f\"figures/UpSet_plot_viral_positive_breakdown_{title_suffix}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not plot UpSet for {title_suffix} (all-viral_label == 1): {e}\")\n",
    "    else:\n",
    "        print(f\"{title_suffix} (all-viral_label == 1): No rows with any *_label == 1 found or only one label present.\")\n",
    "\n",
    "    # --- Bar plot for Malaria_label in all-viral_label == 0 ---\n",
    "    if for_nonviral.empty:\n",
    "        print(f\"{title_suffix} (all-viral_label == 0): No rows found.\")\n",
    "        return\n",
    "\n",
    "    # Confirm that no other *_label column is == 1 except Malaria_label\n",
    "    malaria_col = \"Malaria_label\"\n",
    "    other_label_cols = [col for col in all_label_cols if col != malaria_col]\n",
    "    # For each row, check if all other *_label columns are 0 or NaN\n",
    "    if other_label_cols:\n",
    "        # Find rows where any other *_label column is 1\n",
    "        mask_other_1 = (for_nonviral[other_label_cols].fillna(0).astype(int) == 1)\n",
    "        rows_with_other_1 = mask_other_1.any(axis=1)\n",
    "        if rows_with_other_1.any():\n",
    "            print(f\"WARNING: Some rows in {title_suffix} (all-viral_label == 0) have other *_label columns == 1 besides Malaria_label.\")\n",
    "            # Show which columns are ==1 for these rows\n",
    "            idxs = rows_with_other_1[rows_with_other_1].index\n",
    "            for idx in idxs:\n",
    "                row = for_nonviral.loc[idx, other_label_cols]\n",
    "                cols_with_1 = row[row.fillna(0).astype(int) == 1].index.tolist()\n",
    "                print(f\"  Row index {idx}: columns == 1: {cols_with_1}\")\n",
    "        else:\n",
    "            print(f\"Confirmed: In {title_suffix} (all-viral_label == 0), only Malaria_label is 1; all other *_label columns are 0 or NaN.\")\n",
    "    else:\n",
    "        print(f\"No other *_label columns found except Malaria_label.\")\n",
    "\n",
    "    # Count Malaria_label==0 and Malaria_label==1\n",
    "    malaria_counts = for_nonviral[malaria_col].value_counts().sort_index()\n",
    "    malaria_bar = [malaria_counts.get(0, 0), malaria_counts.get(1, 0)]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    bars = ax.bar([0, 1], malaria_bar, color=['#1f77b4', '#ff7f0e'], width=0.6)\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Malaria_label=0', 'Malaria_label=1'])\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(f\"{title_suffix} (all-viral_label == 0): Malaria_label breakdown\")\n",
    "\n",
    "    # Add value labels\n",
    "    for i, val in enumerate(malaria_bar):\n",
    "        ax.text(i, val + max(1, 0.001 * max(malaria_bar)), str(val), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figures/Malaria_label_barplot_viral_negative_{title_suffix}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_label_upset_and_malaria_bar(test_df_labels, title_suffix=\"Testing Data\")\n",
    "plot_label_upset_and_malaria_bar(train_df_labels, title_suffix=\"Training Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05cf17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ca9f6a3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_07",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
